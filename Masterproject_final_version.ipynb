{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead98d8b",
   "metadata": {},
   "source": [
    "# Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb10bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfaidx import Fasta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from bedparse import bedline\n",
    "import numpy as np\n",
    "import json\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style \n",
    "from pyensembl import Genome\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import os,re\n",
    "from bedparse import bedline\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d489c9f8",
   "metadata": {},
   "source": [
    "# Validating \n",
    "Fast5 raw data are publicly available in SRA under the accession [SRP174366](https://www.ncbi.nlm.nih.gov/sra/?term=SRP174366) \n",
    "The pre-processing were done like described in Material and Methods with the [reference sequence](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE124309) also found in the repository including the processed files from m6Anet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b24264",
   "metadata": {},
   "source": [
    "### Loading m6Anet ouput files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd505d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IVT with m6A instead of adenosine \n",
    "curlcake_mod = pd.read_csv('./IVT/modified/data.result.csv')\n",
    "#IVT unmodified \n",
    "curlcake_non_mod = pd.read_csv('./IVT/non_modified/data.result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed8a1a",
   "metadata": {},
   "source": [
    "### Initialize modified arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identified modifications within modified sequences \n",
    "curlcake_mod_05 = curlcake_mod[curlcake_mod['probability_modified']>0.5]\n",
    "#identified unmodified positions within the unmodified sequence \n",
    "curlcake_non_mod_05 = curlcake_non_mod[curlcake_non_mod['probability_modified']>0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299ef582",
   "metadata": {},
   "source": [
    "### Adding kmer Information to the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dab313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading datapreparation file from m6Anet\n",
    "data_index_mod = pd.read_csv('./IVT/modified/data.index')    \n",
    "read_count_mod = pd.read_csv('./IVT/modified/data.readcount')\n",
    "data_info_mod = data_index_mod.merge(read_count_mod, on=['transcript_id', 'transcript_position'])\n",
    "#filtering for transcripts with equal or more than 20 reads as m6Anet is doing in the analysis\n",
    "data_info_mod = data_info_mod[data_info_mod[\"n_reads\"] >= 20].reset_index(drop=True)\n",
    "\n",
    "#function for loading 5-mer \n",
    "def _load_data_mod(idx):\n",
    "    \"\"\"[function for loading 5-mer from index]\n",
    "\n",
    "    Args:\n",
    "        idx ([int]): [index of the m6Anet output file]\n",
    "\n",
    "    Returns:\n",
    "        [string]: [5-mer of the index position]\n",
    "    \"\"\"  \n",
    "    #reading json file and initialize variables \n",
    "    with open('./IVT/modified/data.json', 'r') as f:\n",
    "        tx_id, tx_pos, start_pos, end_pos = data_info_mod.iloc[idx][[\"transcript_id\", \"transcript_position\",\"start\", \"end\"]]\n",
    "        f.seek(start_pos, 0)\n",
    "        #initialize json file with start end end postion\n",
    "        json_str = f.read(end_pos - start_pos)\n",
    "        #loading json information for certain id on certain position\n",
    "        pos_info = json.loads(json_str)[tx_id][str(tx_pos)]\n",
    "        #ensure that a certain position on the transcript only have a certain kmer \n",
    "        assert(len(pos_info.keys()) == 1)\n",
    "        # separate kmer and other features from datapreparation step of m6Anet\n",
    "        kmer, features = list(pos_info.items())[0]\n",
    "    return kmer\n",
    "\n",
    "###### SAME STEPS ARE DONE FOR THE NOT MODIFIED DATASET #######\n",
    " \n",
    "\n",
    "data_index_nonmod = pd.read_csv('./IVT/not_modified/data.index')    \n",
    "read_count_nonmod = pd.read_csv('./IVT/not_modified/data.readcount')\n",
    "data_info_nonmod = data_index_nonmod.merge(read_count_nonmod, on=['transcript_id', 'transcript_position'])\n",
    "data_info_nonmod = data_info_nonmod[data_info_nonmod[\"n_reads\"] >= 20].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def _load_data_nonmod(idx):\n",
    "    \"\"\"[function for loading 5-mer from index]\n",
    "\n",
    "    Args:\n",
    "        idx ([int]): [index of the m6Anet output file]\n",
    "\n",
    "    Returns:\n",
    "        [string]: [5-mer of the index position]\n",
    "    \"\"\"  \n",
    "    with open('./non_modified/m6anet_dataprep/data.json', 'r') as f:\n",
    "        tx_id, tx_pos, start_pos, end_pos = data_info_nonmod.iloc[idx][[\"transcript_id\", \"transcript_position\",\"start\", \"end\"]]\n",
    "        f.seek(start_pos, 0)\n",
    "        json_str = f.read(end_pos - start_pos)\n",
    "        pos_info = json.loads(json_str)[tx_id][str(tx_pos)]\n",
    "        \n",
    "        assert(len(pos_info.keys()) == 1)\n",
    "\n",
    "        kmer, features = list(pos_info.items())[0]\n",
    "    return kmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d47a3c",
   "metadata": {},
   "source": [
    "### Adding the kmer informations to the m6Anet output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad08d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through the m6Anet output file and initialize the kmer column with the 5-mer's \n",
    "for index,row in curlcake_non_mod.iterrows():\n",
    "    curlcake_non_mod.loc[index,'kmer']=_load_data_nonmod(index)[1:-1]\n",
    "for index,row in curlcake_mod.iterrows():\n",
    "    curlcake_mod.loc[index,'kmer']=_load_data_mod(index)[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e00f1fc",
   "metadata": {},
   "source": [
    "### Counting the ratio of modified 5-mers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a079981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting all 5-mers and storing in a dictionary {kmer:count}\n",
    "letter_counts_all = Counter(list(curlcake_mod['kmer']))\n",
    "#Initialize a DataFrame from dictionary of kmer and count\n",
    "all_kmer = pd.DataFrame.from_dict(letter_counts_all, orient='index')\n",
    "all_kmer.columns = ['count']\n",
    "all_kmer.sort_values(by='count',inplace=True)\n",
    "all_kmer['kmer'] = all_kmer.index\n",
    "#Counting only predicted m6A positions from m6Anet\n",
    "letter_counts_mod = Counter(list(curlcake_mod[curlcake_mod['probability_modified']>0.5]['kmer']))\n",
    "mod_kmer = pd.DataFrame.from_dict(letter_counts_mod, orient='index')\n",
    "mod_kmer.columns=['count_modified']\n",
    "mod_kmer.sort_values(by = 'count_modified',inplace=True)\n",
    "mod_kmer['kmer_mod'] = mod_kmer.index\n",
    "# concat both DataFrames and replace NAs 5-mers and counts with 0 \n",
    "count_list=pd.concat([all_kmer,mod_kmer],axis=1)\n",
    "count_list.fillna(0,inplace=True)\n",
    "\n",
    "# calculate the percentage of identified 5-mers \n",
    "count_list['%'] = ((count_list['count_modified'] / count_list['count']*100))\n",
    "#sort DataFrame by probability of the 5mer is identified by m6Anet and the number of the certain 5-mer occurs in the sequence\n",
    "count_list.sort_values(by=['%','count'],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7259c",
   "metadata": {},
   "source": [
    "### Plotting the probability of a 5-mer being identified by m6Anet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10, 7), dpi=1200)\n",
    "ax=sns.barplot(x='kmer',y='%', data=count_list)\n",
    "ax.set_xticklabels(rotation=90, horizontalalignment='right',labels=count_list['kmer'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09b2ff",
   "metadata": {},
   "source": [
    "### Filtering the m6Anet output file for consecutively m6A positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e22ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a pd.Series with True and False on index where the 5-mer contain a m6A on position -1 \n",
    "double_A = curlcake_mod.kmer.str[1].str.contains('A')\n",
    "#initialize a pd.Series with True and False on index where the 5-mer doesn't contain a m6A on position -1 \n",
    "notdouble = ~double_A\n",
    "#filter for position with and without m6A on position -1\n",
    "without_consecutive_m6A_curlcake = curlcake_mod.query('@notdouble')\n",
    "consecutive_m6a_curlcake = curlcake_mod.query('@double')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88348eb1",
   "metadata": {},
   "source": [
    "### Plotting the percentage ratio of a modified DRACH motif gets identified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba41d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_style('darkgrid')\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10, 7), dpi=200)\n",
    "clrs = ['red' if x[1]=='A' else 'grey' for x in count_list.kmer ]\n",
    "ax=sns.barplot(x='kmer',y='%', data=count_list, palette=clrs)\n",
    "ax.set_xticklabels(rotation=90, horizontalalignment='right',labels=count_list['kmer'])\n",
    "plt.ylabel('identified as modified [%]')\n",
    "plt.ylim(-10,110)\n",
    "plt.hlines(0,xmin=12.7,xmax=13.4)\n",
    "plt.hlines(0,xmin=13.7,xmax=14.4)\n",
    "plt.hlines(0,xmin=14.7,xmax=15.4)\n",
    "plt.hlines(0,xmin=15.7,xmax=16.4)\n",
    "plt.hlines(0,xmin=16.7,xmax=17.4)\n",
    "red_patch = mpatches.Patch(color='red', label='consecutively_m6A_motif')\n",
    "green_patch = mpatches.Patch(color='grey',label='not_consecutively_m6A_motif')\n",
    "plt.legend(handles=[green_patch,red_patch,])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b014d",
   "metadata": {},
   "source": [
    "### Plotting the distribution of the probability_modified values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73df571",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10, 7), dpi=300)\n",
    "\n",
    "sns.distplot(curlcake_mod.probability_modified,bins=30,kde=False,label='modified')\n",
    "sns.distplot(curlcake_non_mod.probability_modified,bins=30,kde=False,label='non modified')\n",
    "sns.distplot(without_consecutive_m6A_curlcake.probability_modified,bins=30,kde=False,label='modified_without_consecutively_m6A_motif')\n",
    "sns.distplot(consecutive_m6a_curlcake.probability_modified,bins=30,kde=False,label='modified_with_consecutively_m6A_motif')\n",
    "black_patch = mpatches.Patch(color='red', label='The red data')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(0,1)\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "sns.set_context('paper') \n",
    "plt.xlabel('probability_modified')\n",
    "plt.ylabel('count')\n",
    "sns.set_style(\"dark\")\n",
    "plt.vlines(0.5,ymin=0,ymax=60,linestyle='--',color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b80a87f",
   "metadata": {},
   "source": [
    "# Loading the reference genome file\n",
    "\n",
    "downloaded from [ensemble](http://nov2020.archive.ensembl.org/Homo_sapiens/Info/Index#:~:text=cDNAs%2C%20ncRNA%2C%20proteins-,Download%20GTF,-or%20GFF3%20files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = Genome(reference_name='GRCh38',\n",
    "                annotation_name='my_genome_features',\n",
    "                gtf_path_or_url='./Homo_sapiens.GRCh38.102.gtf',\n",
    "                transcript_fasta_paths_or_urls='./Homo_sapiens.GRCh38.102.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8253c02",
   "metadata": {},
   "source": [
    "# Loading the m6Anet output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "m6a_1 = pd.read_csv('./polysome_profiling/data.result_monosome.csv')\n",
    "m6a_3 = pd.read_csv('./polysome_profiling/data.result_polysome.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a051a2",
   "metadata": {},
   "source": [
    "# Functions for analyzing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c8b8ac",
   "metadata": {},
   "source": [
    "### adding transcriptomic information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ec4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tx_ref(transcript_ids):\n",
    "    \"\"\"[create pd.DataFrame with the transcript_ids and the respective postions of the regions and the chromosome]\n",
    "\n",
    "    Args:\n",
    "        transcript_ids ([numpy.ndarray]): [unique transcript_ids]\n",
    "\n",
    "    Returns:\n",
    "        [pd:DataFrame]: [transcript_id','end_5utr','end_cds','end_tx','chromosome']\n",
    "    \"\"\"    \n",
    "    #initialize arrays\n",
    "    transcript_lengths = []\n",
    "    #looping through transcript_ids\n",
    "    for tx_id in transcript_ids:\n",
    "        # safe genome information from transcript_id in tx\n",
    "        try:\n",
    "            tx = genome.transcript_by_id(tx_id)\n",
    "        except Exception:\n",
    "            continue\n",
    "        # end of transcript (end_tx) defined as length of sequence\n",
    "        end_tx = len(tx.sequence)\n",
    "        chromosome = tx.contig\n",
    "        \n",
    "        # including only transcripts containing start and stop codon\n",
    "        if tx.contains_start_codon and tx.contains_stop_codon:\n",
    "            end_5utr = len(tx.five_prime_utr_sequence)\n",
    "            \n",
    "            #end of CDS (end_cds) as the position of the last stop codon\n",
    "            end_cds = tx.last_stop_codon_spliced_offset\n",
    "            if end_tx > end_cds > end_5utr > 0:\n",
    "                transcript_lengths += [(tx_id,end_5utr,end_cds,end_tx,chromosome)]\n",
    "    return pd.DataFrame(transcript_lengths,columns= ['transcript_id','end_5utr','end_cds','end_tx','chromosome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c692d79",
   "metadata": {},
   "source": [
    "### calculating the relative m6A positions on the transcript from the m6Anet output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_assign(df):\n",
    "    \"\"\"[calculating the relative positions of m6A]\n",
    "\n",
    "    Args:\n",
    "        df ([pd.DataFrame]): [m6Anet outputfile with transcript_ids and transcript_position]\n",
    "\n",
    "    Returns:\n",
    "        [pd.DataFrame]: [transcript_position assigned to the region and the respective relative position]\n",
    "    \"\"\"    \n",
    "    #Add postions of the regions to df\n",
    "    df = df.merge(create_tx_ref(df.transcript_id.unique()),how='inner',on='transcript_id')\n",
    "    #Assign the postions in df to the region where it is located as boolean\n",
    "    df['isin_5utr'] = df['transcript_position'] < df['end_5utr']\n",
    "    df['isin_cds'] = (~df['isin_5utr']) & (df['transcript_position'] < df['end_cds'])\n",
    "    df['isin_3utr'] = (~df['isin_5utr']) & (~df['isin_cds']) \n",
    "    #Calculate the length of the regions except the length of 5'UTR with is defined by the end of it in df['end_5utr']\n",
    "    len_cds = df['end_cds']-df['end_5utr']\n",
    "    len_3utr = df['end_tx']-df['end_cds']\n",
    "    \n",
    "    #ensure that those requirements are met\n",
    "    assert (len_cds > 0).all()\n",
    "    assert (len_3utr > 0).all()\n",
    "\n",
    "    # calculate the relative length of the positions \n",
    "    rel_len_5utr = df['isin_5utr']*(df['transcript_position']/df['end_5utr'])\n",
    "    rel_len_cds = df['isin_cds']*((df['transcript_position']-df['end_5utr'])/len_cds)\n",
    "    rel_len_3utr = df['isin_3utr']*((df['transcript_position']-df['end_cds'])/len_3utr)\n",
    "    \n",
    "    df['rel_5utr'] = rel_len_5utr\n",
    "    df['rel_cds'] = rel_len_cds\n",
    "    df['rel_3utr'] = rel_len_3utr\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f9ec9",
   "metadata": {},
   "source": [
    "### refering to create_tx_ref but creating a list of length of certain regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed968900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tx_ref_region_length(transcript_ids,region):\n",
    "    \"\"\"[creating a list of containing the lengths of regions of respective transcript_id]\n",
    "\n",
    "    Args:\n",
    "        transcript_ids ([numpy.ndarray]): [unique transcript_ids]\n",
    "        region ([str]): [region of interest:['5utr','cds','3utr']]\n",
    "\n",
    "    Returns:\n",
    "        [list]: [list of lengths of regions of respective transcript_id ]\n",
    "    \"\"\"    \n",
    "    #initialize array \n",
    "    transcript_lengths = []\n",
    "    if region=='5utr':\n",
    "        for tx_id in transcript_ids:\n",
    "            try:\n",
    "                tx = genome.transcript_by_id(tx_id)\n",
    "            except Exception:\n",
    "                continue\n",
    "            five = len(tx.five_prime_utr_sequence)\n",
    "            transcript_lengths.append(five)\n",
    "    if region == 'cds':\n",
    "        for tx_id in transcript_ids:\n",
    "            try:\n",
    "                tx = genome.transcript_by_id(tx_id)\n",
    "            except Exception:\n",
    "                continue\n",
    "            end_5utr = len(tx.five_prime_utr_sequence)\n",
    "            end_cds = tx.last_stop_codon_spliced_offset\n",
    "            cds=end_cds-end_5utr\n",
    "            transcript_lengths.append(cds)\n",
    "    if region == '3utr':\n",
    "        for tx_id in transcript_ids:\n",
    "            try:\n",
    "                tx = genome.transcript_by_id(tx_id)\n",
    "            except Exception:\n",
    "                continue\n",
    "            end_cds = tx.last_stop_codon_spliced_offset\n",
    "            three=len(tx.sequence)-end_cds\n",
    "            transcript_lengths.append(three)\n",
    "\n",
    "    return transcript_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec13863",
   "metadata": {},
   "source": [
    "## Metagene plot\n",
    "### plotting the relative positions on the transcriptome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rel_positions(ax,df, label):\n",
    "    \"\"\"[transcriptome wide plotting of m6A positions]\n",
    "\n",
    "    Args:\n",
    "        ax ([ax]): [ax]\n",
    "        df ([pd.DataFrame]): [DataFrame containing transcript_positions and transcript_id]\n",
    "        label ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"    \n",
    "\n",
    "\n",
    "    #Add postions of the regions to df\n",
    "    df = df.merge(create_tx_ref(df),how='inner',on='transcript_id')\n",
    "    #Assign the postions in df to the region as boolean \n",
    "    df['isin_5utr'] = df['transcript_position'] < df['end_5utr']\n",
    "    df['isin_cds'] = (~df['isin_5utr']) & (df['transcript_position'] < df['end_cds'])\n",
    "    df['isin_3utr'] = (~df['isin_5utr']) & (~df['isin_cds']) \n",
    "    #Calculate the length of the regions except the length of 5'UTR with is defined by the end of it in df['end_5utr']\n",
    "    len_cds = df['end_cds']-df['end_5utr']\n",
    "    len_3utr = df['end_tx']-df['end_cds']\n",
    "    \n",
    "    #ensure that those requirements are met\n",
    "    assert (len_cds > 0).all()\n",
    "    assert (len_3utr > 0).all()\n",
    "\n",
    "    #calculate the relative length of the positions \n",
    "    rel_len_5utr = df['isin_5utr']*(df['transcript_position']/df['end_5utr'])\n",
    "    rel_len_cds = df['isin_cds']*((df['transcript_position']-df['end_5utr'])/len_cds)\n",
    "    rel_len_3utr = df['isin_3utr']*((df['transcript_position']-df['end_cds'])/len_3utr)\n",
    "    #Initialize the relative positions\n",
    "    rel_positions = list(rel_len_5utr[rel_len_5utr>0])\n",
    "    rel_positions += list(rel_len_cds[rel_len_cds>0] + 1)\n",
    "    rel_positions += list(rel_len_3utr[rel_len_3utr>0] +2)\n",
    "    #ploting the relative positions in a Kernel Density Estimate plot using Gaussian kernels\n",
    "    sns.kdeplot(rel_positions, ax=ax, label=label, shade=True, cut=True)\n",
    "    ax.set_xticks([])\n",
    "    \n",
    "    plt.yticks(fontsize=14)\n",
    "    #annotating the x axis \n",
    "    trans = ax.get_xaxis_transform()\n",
    "    ax.plot([-.05,1],[-.08,-.08], color=\"k\", transform=trans, clip_on=False,linewidth=7.0)\n",
    "    ax.annotate(\"5'UTR\",xy=(0.5, -0.1),xytext=(0.5,-0.1),             \n",
    "                annotation_clip=False,fontsize=20)\n",
    "    ax.plot([1,2],[-.08,-.08], color=\"k\", transform=trans, clip_on=False,linewidth=20.0)\n",
    "    ax.annotate(\"CDS\",xy=(1.5, -0.1),xytext=(1.5,-0.1),             \n",
    "                annotation_clip=False,fontsize=20)\n",
    "    ax.plot([2,3],[-.08,-.08], color=\"k\", transform=trans, clip_on=False,linewidth=7.0)\n",
    "    ax.annotate(\"3'UTR\",xy=(2.5, -0.1),xytext=(2.5,-0.1),             \n",
    "                annotation_clip=False,fontsize=20)\n",
    "    ax.axvline(1, ymin=0, color='black', linestyle=\"--\")\n",
    "    ax.axvline(2, ymin=0, color='black', linestyle=\"--\")\n",
    "    ax.set_xlim([0,3])\n",
    "    ax.set_ylabel('density',fontsize=16)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11f9c6",
   "metadata": {},
   "source": [
    "### Count of modification per transcript and optional for region and calculating the respective modification status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c17f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mod(df,fraction,region='all'):\n",
    "    \"\"\"[count of modification per transcript and optional for region and calculating the respective modification status]\n",
    "\n",
    "    Args:\n",
    "        df ([pd.DataFrame]): [DataFrame containing transcript_positions and transcript_id]\n",
    "        fraction ([str]): ['polysome','monosome']\n",
    "        region (str, optional): [region of interest:['5utr','cds','3utr']]. Defaults to 'all'.\n",
    "\n",
    "    Returns:\n",
    "        [pd.DataFrame]: [DataFrame with number modification, length and modification of respective transcript_id]\n",
    "    \"\"\"    \n",
    "\n",
    "    #calculating modification status of each transcript without region\n",
    "    if region == 'all':\n",
    "        df1=pd.concat([df.transcript_id.value_counts()],axis=1,keys=[fraction])\n",
    "        df1['length']= create_tx_ref(list(df1.index))\n",
    "        df1['mod_status'] = df1[fraction]/df1['length']\n",
    "    #calculating modification status of each transcript with region information and regional modification status\n",
    "    elif region != 'all':\n",
    "        #counting transcript_ids with modifications in certain region\n",
    "        df1=pd.concat([df[df['isin_'+str(region)]==True].transcript_id.value_counts()],axis=1,keys=[str(fraction + ' ' + region)])\n",
    "        #initialize length of the transcript\n",
    "        df1['length']= list(create_tx_ref(list(df1.index)).end_tx)\n",
    "        #initialize modification status of the region\n",
    "        df1['mod_status'] = df1[str(fraction+ ' ' + region)]/df1['length']\n",
    "        #initialize the length of the region\n",
    "        df1[region+'_length']= create_tx_ref_region_length(list(df1.index),region)\n",
    "        df1['mod_status_'+region] = df1[str(fraction+ ' ' + region)]/df1[region+'_length']\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cce398",
   "metadata": {},
   "source": [
    "## Filtering steps of the m6Anet output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a8f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the index as a column\n",
    "m6a_1['index']= m6a_1.index\n",
    "m6a_3['index']=m6a_3.index\n",
    "# filter fractions for modified positions\n",
    "m6a_3_mod=m6a_3[m6a_3['probability_modified']>0.5]\n",
    "m6a_3_mod= region_assign(m6a_3_mod)\n",
    "\n",
    "m6a_1_mod=m6a_1[m6a_1['probability_modified']>0.5]\n",
    "m6a_1_mod= region_assign(m6a_1_mod)\n",
    "\n",
    "#list of processed transcripts \n",
    "m6a_3_transcript_li=list(set(m6a_3.transcript_id))\n",
    "m6a_1_transcript_li=list(set(m6a_1.transcript_id))\n",
    "#list of transcripts with no modifications in fractions\n",
    "m6a_3_transcript_zero = list(set(m6a_3[~m6a_3['transcript_id'].isin(list(set(m6a_3_mod.transcript_id)))]['transcript_id']))\n",
    "m6a_1_transcript_zero = list(set(m6a_1[~m6a_1['transcript_id'].isin(list(set(m6a_1_mod.transcript_id)))]['transcript_id']))\n",
    "#list of transcripts with modifications in fractions\n",
    "m6a_3_transcript_mod=list(set(m6a_3_mod.transcript_id))\n",
    "m6a_1_transcript_mod=list(set(m6a_1_mod.transcript_id))\n",
    "\n",
    "#initialize differential modified positions\n",
    "m6a_diff_poly= pd.merge(m6a_3, m6a_1, on=['transcript_id','transcript_position'],how='left')\n",
    "m6a_diff_mono= pd.merge(m6a_1, m6a_3, on=['transcript_id','transcript_position'],how='left')\n",
    "\n",
    "#positions modified in one fraction and unmodified in the other fraction\n",
    "m6a_diff_poly_only2=m6a_diff_poly[(m6a_diff_poly['probability_modified_y']<0.5)&(m6a_diff_poly['probability_modified_x']>0.5)]\n",
    "m6a_diff_mono_only2=m6a_diff_mono[(m6a_diff_mono['probability_modified_y']<0.5)&(m6a_diff_mono['probability_modified_x']>0.5)]\n",
    "#initialize differential modified positions per fraction and assign the region information\n",
    "m6a_3_diff_mod=m6a_diff_poly_only2[['transcript_id','transcript_position','n_reads_x', 'probability_modified_x']]\n",
    "#m6a_3_diff_mod=region_assign(m6a_3_diff_mod)\n",
    "\n",
    "m6a_1_diff_mod=m6a_diff_mono_only2[['transcript_id','transcript_position','n_reads_x', 'probability_modified_x']]\n",
    "#m6a_1_diff_mod=region_assign(m6a_1_diff_mod)\n",
    "\n",
    "#list of differential modified positions\n",
    "m6a_1_diffmodpos_trans = list(set(m6a_1_diff_mod.transcript_id))\n",
    "m6a_3_diffmodpos_trans = list(set(m6a_3_diff_mod.transcript_id))\n",
    "\n",
    "#filter for transcripts in fraction which are differential modified in the other fraction\n",
    "m6a_3_test_on_monosome = m6a_3_diff_mod[m6a_3_diff_mod['transcript_id'].isin(m6a_1_diffmodpos_trans)]\n",
    "m6a_1_test_on_polysome = m6a_1_diff_mod[m6a_1_diff_mod['transcript_id'].isin(m6a_3_diffmodpos_trans)]\n",
    "#filter for transcripts in fraction which are not differential modified in the other fraction\n",
    "m6a_3_test_noton_monosome = m6a_3_diff_mod[~m6a_3_diff_mod['transcript_id'].isin(m6a_1_diffmodpos_trans)]\n",
    "m6a_1_test_noton_polysome = m6a_1_diff_mod[~m6a_1_diff_mod['transcript_id'].isin(m6a_3_diffmodpos_trans)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cdb7b1",
   "metadata": {},
   "source": [
    "# Plotting the relation between the length and the number of modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize list of lengths\n",
    "list_of_length1=[]\n",
    "#initialize list of modificationnumber in a range of 1 to 30 because no transcript with more modifications then 29\n",
    "list_of_mod1=list(range(1,30))\n",
    "for elem in list_of_mod1:\n",
    "    # Assigning the length of 0 for transcripts without a certain number of modifications\n",
    "    if len(list(count_mod(m6a_1_mod,'monosome')\\\n",
    "                                [count_mod(m6a_1_mod,'monosome')['monosome']==elem]\\\n",
    "                                       ['length'].values))==0:\n",
    "        list_of_length1.append(list(np.random.normal(0,0,100)))\n",
    "    # Assinging the a list length of transcripts with certain modification number\n",
    "    else:\n",
    "        list_of_length1.append(list(count_mod(m6a_1_mod,'monosome')\\\n",
    "                                [count_mod(m6a_1_mod,'monosome')['monosome']==elem]['length'].values))\n",
    "# initialize a dictionary with the number of modification and the respective lengths of the transcripts\n",
    "m_dict = {key: value for key, value in zip(list_of_mod1, list_of_length1)}\n",
    "\n",
    "###### SAME STEPS ARE DONE FOR THE POLYSOME FRACTION #######\n",
    "\n",
    "list_of_length3=[]\n",
    "list_of_mod3=list(range(1,30))\n",
    "for elem in list_of_mod3:\n",
    "    if len(list(count_mod(m6a_3_mod,'polysome')\\\n",
    "                                [count_mod(m6a_3_mod,'polysome')['polysome']==elem]\\\n",
    "                ['length'].values))==0:\n",
    "        list_of_length3.append(list(np.random.normal(0,0,100)))\n",
    "        \n",
    "    else:\n",
    "        list_of_length3.append(list(count_mod(m6a_3_mod,'polysome')\\\n",
    "                                 [count_mod(m6a_3_mod,'polysome')['polysome']==elem]['length'].values))\n",
    "p_dict = {key: value for key, value in zip(list_of_mod3, list_of_length3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1bcfd9",
   "metadata": {},
   "source": [
    "## plotting the length of the transcripts vs. the number of modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "f, axs = plt.subplots(1,2,figsize=(30,8),sharey=True)\n",
    "axs[0].boxplot(m_dict.values())\n",
    "axs[0].set_xticklabels(m_dict.keys())\n",
    "axs[0].set_title('length and n_mod. in monosome')\n",
    "axs[1].boxplot(p_dict.values())\n",
    "axs[1].set_xticklabels(p_dict.keys())\n",
    "axs[1].set_title('length and n_mod in polysome')\n",
    "for ax in axs.flatten():\n",
    "    ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    ax.yaxis.set_tick_params(labelleft=True)\n",
    "\n",
    "axs[0].set_xlabel('n_mod')\n",
    "axs[1].set_xlabel('n_mod')\n",
    "axs[0].set_ylabel('transcripts length')\n",
    "axs[1].set_ylabel('transcripts length')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f681465",
   "metadata": {},
   "source": [
    "# Plotting the distributions of the modification status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace948fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axs = plt.subplots(1, figsize=(20, 12))\n",
    "csfont = {'fontname':'Times New Roman'}\n",
    "sns.distplot(\\\n",
    "             #count_mod(region_assign(m6a_3_diff_mod,'polysome','cds')['mod_status']\\\n",
    "             #count_mod(region_assign(m6a_3_diff_mod,'polysome')['mod_status']\\\n",
    "             #count_mod(m6a_3_mod,'polysome')['mod_status']\\\n",
    "             #count_mod(region_assign(m6a_3_test_on_monosome ),'polysome','cds')['mod_status']\\\n",
    "             #count_mod(region123_fast(m6a_diff_poly_only1_notin1),'polysome','3utr','3utr')['length'])\\\n",
    "             ,color='r',label='polysome',bins=50,kde=False,norm_hist=True,hist_kws= {'histtype':'stepfilled', 'alpha':0.3, 'ec':\"k\"})\n",
    "sns.distplot(\\\n",
    "             #count_mod(m6a_1_mod,'monosome')['mod_status']\\\n",
    "             #count_mod(region_123_fast,'monosome','cds','3utr')['3utr_length']\\\n",
    "             #count_mod(region123_fast(m6a_1[m6a_1['probability_modified']<0.5]),'monosome')['length']\\\n",
    "             #count_mod(region123_fast(m6a_diff_mono_only1_notin3),'monosome','cds','3utr')['mod_status_cds']\\\n",
    "             #count_mod(region123_fast(m6a_diff_mono_only1_notin3),'monosome','3utr','cds')['length'])\\\n",
    "             ,color='b',label='monosome',bins=50,kde=False,norm_hist=True,hist_kws= {'histtype':'stepfilled', 'alpha':0.3,'density': True, 'ec':\"k\"})\n",
    "plt.xlabel('mod_status_new',fontsize=16)\n",
    "plt.ylabel('density',fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8144235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb669a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
